{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "transfer_learning_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW0PQDxc-RAB"
      },
      "source": [
        "# Transfer Learning in Keras\n",
        "\n",
        "In this notebook, we'll cover how to load a pre-trained model (in this case, VGGNet19) and finetune it for a new task: Oxford Flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I3gW4Ve-RAC"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lnecf3Z-RAD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "\n",
        "# from keras.applications.vgg19 import VGG19\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EE3cFdn_LzV"
      },
      "source": [
        "#!pip install tflearn\n",
        "\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "X, Y = oxflower17.load_data(one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMf-k04h-RAD"
      },
      "source": [
        "#### Load the pre-trained VGG19 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3wm-sUE6-RAE"
      },
      "source": [
        "vgg19 = VGG19(include_top=False,\n",
        "              weights='imagenet',\n",
        "              input_shape=(224,224,3),\n",
        "              pooling=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fukH-O-RAE"
      },
      "source": [
        "#### Freeze all the layers in the base VGGNet19 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qsyt0Pn1-RAE"
      },
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz-Q5sJC-RAE"
      },
      "source": [
        "#### Add custom classification layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GWYqWdxY-RAF"
      },
      "source": [
        "# Instantiate the sequential model and add the VGG19 model: \n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "\n",
        "# Add the custom layers atop the VGG19 model: \n",
        "model.add(Flatten(name='flattened'))\n",
        "model.add(Dropout(0.5, name='dropout'))\n",
        "model.add(Dense(17, activation='softmax', name='predictions'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7XhyRM-RAF"
      },
      "source": [
        "#### Compile the model for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "w3S_3yka-RAF"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFx8Yz4gBH-Q"
      },
      "source": [
        "model.fit(X, Y, batch_size=64, epochs=10, verbose=1, validation_split=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlfPw0aa-RAF"
      },
      "source": [
        "#### Using Image Generator\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8mqWyRjSdnd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split train and test data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uPCHfTwR-RAG"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Instantiate two image generator classes:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last',\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Fkmp6CqZ-RAG"
      },
      "source": [
        "# Define the batch size:\n",
        "batch_size=64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDk4H1H-RAG"
      },
      "source": [
        "# Define the train and validation generators: \n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True, seed=42)\n",
        "\n",
        "valid_generator = valid_datagen.flow(X_valid, y_valid, batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m4C-K-y-RAH"
      },
      "source": [
        "model.fit(train_generator, steps_per_epoch=15, epochs=10, validation_data=valid_generator, validation_steps=15, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}